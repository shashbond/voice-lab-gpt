{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voice_lab_gpt_title"
   },
   "source": [
    "# üéôÔ∏è Voice Lab GPT - Google Colab Demo\n",
    "\n",
    "Professional voice and speech analysis system running in Google Colab.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-org/voice-lab-gpt/blob/main/notebooks/Voice_Lab_GPT_Colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "!apt-get update -qq\n",
    "!apt-get install -y libsndfile1 ffmpeg\n",
    "\n",
    "# Install Python packages\n",
    "!pip install numpy scipy librosa praat-parselmouth matplotlib seaborn pandas\n",
    "!pip install jinja2 pyloudnorm pydub scikit-learn plotly\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Voice Lab GPT repository\n",
    "!git clone https://github.com/your-org/voice-lab-gpt.git\n",
    "%cd voice-lab-gpt\n",
    "!pip install -e .\n",
    "\n",
    "print(\"‚úÖ Voice Lab GPT installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from voice_lab import VoiceLabGPT\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display, HTML\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize Voice Lab GPT\n",
    "voice_lab = VoiceLabGPT(enable_visualizations=True)\n",
    "\n",
    "print(\"üéôÔ∏è Voice Lab GPT initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic voice sample for demo\n",
    "def generate_demo_voice(condition='normal'):\n",
    "    sr = 16000\n",
    "    duration = 3.0\n",
    "    t = np.linspace(0, duration, int(sr * duration))\n",
    "    \n",
    "    conditions = {\n",
    "        'normal': {'f0': 150, 'jitter': 0.005, 'shimmer': 0.02, 'noise': 0.01},\n",
    "        'breathy': {'f0': 140, 'jitter': 0.008, 'shimmer': 0.04, 'noise': 0.15},\n",
    "        'rough': {'f0': 160, 'jitter': 0.030, 'shimmer': 0.12, 'noise': 0.02}\n",
    "    }\n",
    "    \n",
    "    params = conditions[condition]\n",
    "    f0 = params['f0']\n",
    "    \n",
    "    # Generate harmonic series with perturbations\n",
    "    audio = np.zeros_like(t)\n",
    "    for h in range(1, 6):\n",
    "        jitter_noise = params['jitter'] * np.random.randn(len(t))\n",
    "        shimmer_noise = params['shimmer'] * np.random.randn(len(t))\n",
    "        \n",
    "        frequency = f0 * h * (1 + jitter_noise)\n",
    "        amplitude = (1.0 / h) * (1 + shimmer_noise)\n",
    "        \n",
    "        audio += amplitude * np.sin(2 * np.pi * frequency * t)\n",
    "    \n",
    "    # Add noise\n",
    "    audio += params['noise'] * np.random.randn(len(t))\n",
    "    \n",
    "    # Normalize\n",
    "    audio = audio / np.max(np.abs(audio)) * 0.8\n",
    "    \n",
    "    return audio, sr\n",
    "\n",
    "# Generate and play demo audio\n",
    "demo_audio, sr = generate_demo_voice('normal')\n",
    "\n",
    "print(\"üéµ Generated demo voice sample:\")\n",
    "display(Audio(demo_audio, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the demo voice\n",
    "print(\"üî¨ Analyzing voice sample...\")\n",
    "\n",
    "results = voice_lab.analyze_audio_array(\n",
    "    demo_audio,\n",
    "    voice_type='female',\n",
    "    patient_info='Demo - Normal Voice',\n",
    "    task_description='Sustained /a/ vowel (synthetic)',\n",
    "    generate_reports=True,\n",
    "    generate_visualizations=True\n",
    ")\n",
    "\n",
    "if 'error' not in results:\n",
    "    print(\"‚úÖ Analysis completed successfully!\")\n",
    "    \n",
    "    # Display key results\n",
    "    grbas = results['grbas_results']\n",
    "    acoustic = results['acoustic_features']\n",
    "    clinical = results['clinical_results']\n",
    "    \n",
    "    print(f\"\\nüìä GRBAS: G{grbas['G']}R{grbas['R']}B{grbas['B']}A{grbas['A']}S{grbas['S']}\")\n",
    "    print(f\"üè• Primary Impression: {clinical['primary_impression']['condition'].replace('_', ' ').title()}\")\n",
    "    print(f\"üéØ Confidence: {clinical['primary_impression']['confidence']:.0%}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Analysis failed: {results['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display clinical summary\n",
    "if 'error' not in results:\n",
    "    summary = voice_lab.get_clinical_summary(results)\n",
    "    print(\"üìã Clinical Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display visualizations if available\n",
    "if results.get('visualizations'):\n",
    "    print(\"üìà Generated Visualizations:\")\n",
    "    \n",
    "    for plot_name, plot_data in results['visualizations'].items():\n",
    "        if plot_name != 'error' and isinstance(plot_data, str):\n",
    "            # Decode base64 image and display\n",
    "            try:\n",
    "                img_bytes = base64.b64decode(plot_data)\n",
    "                display(HTML(f'<h3>{plot_name.replace(\"_\", \" \").title()}</h3>'))\n",
    "                display(HTML(f'<img src=\"data:image/png;base64,{plot_data}\" style=\"max-width: 100%; height: auto;\"/>'))\n",
    "            except:\n",
    "                print(f\"Could not display {plot_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Your Own Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import librosa\n",
    "\n",
    "# Upload audio file\n",
    "print(\"üìÅ Upload your audio file (WAV, MP3, etc.):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    print(f\"‚úÖ Uploaded: {filename}\")\n",
    "    \n",
    "    # Load and play the uploaded audio\n",
    "    audio, sr = librosa.load(filename, sr=None)\n",
    "    display(Audio(audio, rate=sr))\n",
    "    \n",
    "    # Analyze the uploaded audio\n",
    "    print(\"üî¨ Analyzing uploaded audio...\")\n",
    "    \n",
    "    user_results = voice_lab.analyze_audio_array(\n",
    "        audio,\n",
    "        voice_type=None,  # Auto-detect\n",
    "        patient_info=f'User Upload - {filename}',\n",
    "        task_description='User provided audio',\n",
    "        generate_reports=True,\n",
    "        generate_visualizations=True\n",
    "    )\n",
    "    \n",
    "    if 'error' not in user_results:\n",
    "        print(\"‚úÖ Analysis completed!\")\n",
    "        \n",
    "        # Display results\n",
    "        summary = voice_lab.get_clinical_summary(user_results)\n",
    "        print(\"\\nüìã Your Audio Analysis:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(summary)\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Analysis failed: {user_results['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Voice Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and analyze different voice conditions\n",
    "conditions = ['normal', 'breathy', 'rough']\n",
    "condition_results = {}\n",
    "\n",
    "print(\"üî¨ Analyzing different voice conditions...\")\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"\\nAnalyzing {condition} voice...\")\n",
    "    \n",
    "    # Generate audio for this condition\n",
    "    audio, sr = generate_demo_voice(condition)\n",
    "    \n",
    "    # Analyze\n",
    "    results = voice_lab.analyze_audio_array(\n",
    "        audio,\n",
    "        voice_type='female',\n",
    "        patient_info=f'Demo - {condition.title()} Voice',\n",
    "        generate_reports=False,\n",
    "        generate_visualizations=False\n",
    "    )\n",
    "    \n",
    "    condition_results[condition] = results\n",
    "    \n",
    "    if 'error' not in results:\n",
    "        grbas = results['grbas_results']\n",
    "        clinical = results['clinical_results']\n",
    "        \n",
    "        grbas_str = f\"G{grbas['G']}R{grbas['R']}B{grbas['B']}A{grbas['A']}S{grbas['S']}\"\n",
    "        impression = clinical['primary_impression']['condition'].replace('_', ' ').title()\n",
    "        confidence = clinical['primary_impression']['confidence']\n",
    "        \n",
    "        print(f\"  GRBAS: {grbas_str}\")\n",
    "        print(f\"  Impression: {impression} ({confidence:.0%})\")\n",
    "        \n",
    "        # Play audio sample\n",
    "        display(HTML(f'<h4>{condition.title()} Voice Sample:</h4>'))\n",
    "        display(Audio(audio, rate=sr))\n",
    "    \n",
    "    else:\n",
    "        print(f\"  ‚ùå Analysis failed: {results['error']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Condition comparison completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reports and download\n",
    "if 'results' in locals() and 'error' not in results:\n",
    "    # Create reports directory\n",
    "    !mkdir -p reports\n",
    "    \n",
    "    # Save reports\n",
    "    saved_files = voice_lab.save_reports(\n",
    "        output_dir='./reports',\n",
    "        results=results,\n",
    "        formats=['json', 'html', 'clinical_summary']\n",
    "    )\n",
    "    \n",
    "    print(\"üìÅ Reports saved:\")\n",
    "    for format_type, filepath in saved_files.items():\n",
    "        print(f\"  ‚úì {format_type}: {filepath}\")\n",
    "    \n",
    "    # Download files\n",
    "    print(\"\\n‚¨áÔ∏è Downloading reports...\")\n",
    "    for filepath in saved_files.values():\n",
    "        files.download(filepath)\n",
    "    \n",
    "    print(\"‚úÖ Reports downloaded to your computer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "üéâ **Congratulations!** You've successfully run Voice Lab GPT in Google Colab.\n",
    "\n",
    "### What you can do next:\n",
    "- Upload your own voice recordings for analysis\n",
    "- Experiment with different voice conditions\n",
    "- Download and examine the generated reports\n",
    "- Integrate Voice Lab GPT into your research or clinical workflow\n",
    "\n",
    "### For production use:\n",
    "- Install Voice Lab GPT on your local machine or server\n",
    "- Set up batch processing for multiple files\n",
    "- Integrate with your existing clinical systems\n",
    "\n",
    "### Resources:\n",
    "- [GitHub Repository](https://github.com/your-org/voice-lab-gpt)\n",
    "- [Documentation](https://voice-lab-gpt.readthedocs.io)\n",
    "- [Research Papers](https://voice-lab-gpt.readthedocs.io/references)\n",
    "\n",
    "---\n",
    "\n",
    "**ü§ñ Generated with Voice Lab GPT**\n",
    "\n",
    "*Professional voice analysis for clinical excellence*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}